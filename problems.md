| № | **Проблема (как видит бизнес)**                                       | **Почему сейчас не решается**                                                                                       | **Как решит новая архитектура (Data Mesh + Lakehouse)**                                                                                                             |
| - | --------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1 | **«Чтобы подключить новый бизнес, нужно перекраивать склад данных»**  | Вся логика прошита в одном MSSQL‑складе: новые таблицы, процедуры, отчёты — всё руками, иначе рушится существующее. | Каждый бизнес‑домен публикует свои «продукты данных» в Iceberg; схемы версионируются через Nessie. Dremio подхватывает их без переписывания централизованного кода. |
| 2 | **«Мы ждём отчёт неделями, потому что ИТ пишет его с нуля»**          | Power BI связан напрямую с DWH; любой новый срез → новый SQL‑скрипт и ручная работа BI‑команды.                     | Self‑service‑портал (Superset + Dremio): данные доступны сразу после загрузки, пользователь сам конструирует отчёт drag‑and‑drop.                                   |
| 3 | **«Нет чёткого разграничения: либо вижу всё, либо ничего»**           | Права задаются на уровне базы; тонкая настройка = ручные представления, тяжело поддерживать.                        | Keycloak + Dremio: ролевая модель на уровне столбцов/строк; DataHub хранит, кто чем владеет, — доступ контролируется политиками.                                    |
| 4 | **«Боюсь ломать чужие отчёты, если изменю данные»**                   | В MSSQL нет контроля версий схем; любое изменение таблицы рискованно.                                               | Nessie даёт «Git для данных»: ветка‑тест → проверка → merge; при ошибке легко откатиться.                                                                           |
| 5 | **«И Т‑команда чинит падения загрузки постфактум»**                   | ETL зашит в Camel‑роутах; мониторинг слабый, ретраев нет.                                                           | Airflow управляет всеми пайплайнами: граф зависимостей, алерты, автоматический повтор.                                                                              |
| 6 | **«Медицинские карточки мешаются в отчётах, а показывать их нельзя»** | Всё хранится в одном DWH, нужно вручную чистить данные под каждый отчёт.                                            | Медицинские PII остаются в источниках; в витрину попадают только обезличенные агрегаты Iceberg, отмеченные тегами в DataHub.                                        |
| 7 | **«Интеграционная шина устарела и не держит нагрузку»**               | Camel‑роуты сложно масштабировать и сопровождать; новые источники подключаются долго.                               | Kafka + Kafka Connect берут на себя потоковые данные; добавление нового источника — конфиг, без кода.                                                               |
| 8 | **«AI‑команда возится с выгрузками вручную»**                         | Нет удобного способа брать свежие датасеты и повторять эксперименты.                                                | ML‑сервисы читают Iceberg‑версии напрямую из Dremio; time‑travel и чёткое lineage обеспечивают воспроизводимость.                                                   |
| 9 | **«Рост объёма данных тормозит отчёты»**                              | MSSQL масштабируется вертикально; при росте данных — задержки в BI часами.                                          | Iceberg на объектном хранилище масштабируется горизонтально; Dremio кеширует горячие данные, отчёты остаются быстрыми.                                              |


1. Финтех-сервисы
Проблема:
Финансовые расчёты (например, взаиморасчёты с клиниками и пациентами, учёт оплат, тарифы) реализуются в отдельных сервисах, но данные для них поступают с задержками или вручную — высокая стоимость интеграции, много ручной сверки.

Текущее решение:
Финтех-сервисы получают данные через Apache Camel или выгрузки из DWH. Задержки, нет стандартизированного API, нет события о появлении новых данных.

Новое решение:
Kafka + стандартизированные потоки данных (CDC, топики событий). Финтех-сервисы подписываются на нужные события (оплата прошла, статус услуги изменился) и работают в почти реальном времени. Становятся слабо связаны с источниками, упрощается поддержка.

2. Внутренняя медицинская система + DWH с интерфейсом
Проблема:
Вся логика — и для операторов, и для аналитиков — построена на одном монолитном хранилище. Операторы используют PowerBuilder, отчёты строятся на тех же данных, что и внутренние процессы. Всё завязано на MSSQL.

Текущее решение:
PowerBuilder работает напрямую с DWH. Внутри DWH много бизнес-логики, нет чёткого разделения между оперативными и аналитическими задачами. Любое изменение может затронуть и BI, и операционку.

Новое решение:
Разделение: внутренняя система остаётся для работы операторов, а аналитика уходит в витрину на базе Iceberg (Lakehouse). Там — только согласованные и обезличенные данные. Операции и аналитика больше не мешают друг другу.

3. Много кастомизаций BI-системы поверх DWH
Проблема:
BI-система обросла ручными настройками, отдельными SQL-запросами, множеством версий одних и тех же отчётов. Поддерживать дорого, сложно передавать между отделами.

Текущее решение:
Power BI подключён к MSSQL, строит отчёты на кастомных представлениях и таблицах. Для каждого направления свои скрипты, бизнес-логика дублируется.

Новое решение:
Используется витрина (Dremio + Superset или Power BI), где источником выступают Iceberg-таблицы. Они версионируются, управляются как дата-продукты. Каталог (DataHub) показывает, кто отвечает за что. Конструктор отчётов доступен бизнесу, не нужно писать SQL вручную.

4. ИИ-сервисы для работы с медицинскими данными
Проблема:
Модели обучаются на выгрузках вручную. Данные обезличиваются скриптами, нет воспроизводимости, непонятно, какая версия использовалась. Много разногласий по качеству данных.

Текущее решение:
ИИ-команда берёт CSV-файлы из MSSQL или выгрузки из Camel. У каждого дата-сета своя структура, нет lineage, нет контроля версий.

Новое решение:
Iceberg + Nessie: датасеты — это версионируемые таблицы. Модель обучается на конкретной ветке, можно воспроизвести эксперимент. Dremio позволяет быстро подгрузить датасет в нужном виде. Вся история lineage сохраняется.

5. Слой интеграций через старую шину данных (Apache Camel)
Проблема:
Camel требует ручной настройки, плохо масштабируется, сложно мониторить. Подключение новых источников данных занимает недели.

Текущее решение:
Все сервисы обмениваются данными через Camel — XML/HTTP, трансформации вручную, часто ломается, плохо логируется.

Новое решение:
Kafka + Kafka Connect. Потоки событий (например, изменение статуса заказа, новая оплата) доступны подписчикам. Новые источники подключаются декларативно. Поддержка и масштабирование проще, контроль через UI и алерты.


тут все техника, надо идти от целей и почему текущая архитектура не решает жти задачи и как новая решит

### **Проблемы и цели трансформации архитектуры данных**  
**Приоритеты: 1 (критично) → 3 (можно отложить)**  

---

#### **1. Промежуточное состояние (2 месяца)**  
| **Цель** | **Проблема в текущем решении** | **Приоритет** |  
|----------|--------------------------------|---------------|  
| Уточнить границы доменов (финтех, клиники, ИИ) | Нет чёткого разделения данных между командами, дублирование ETL-логики | 1 |  
| Запланировать проекты по витринам данных | Витрины зависят от монолитного DWH, что замедляет разработку | 1 |  
| Начать миграцию аналитики из DWH в Lakehouse | DWH (MSSQL 2008) не масштабируется, медленные запросы | 1 |  
| Интегрировать DataHub для управления метаданными | Метаданные разрознены, нет единого каталога | 2 |  
| Настроить Kafka для потоковой интеграции | Шина Camel не поддерживает event-driven архитектуру | 2 |  

---

#### **2. Финальное состояние (1 год)**  
| **Цель** | **Проблема в текущем решении** | **Приоритет** |  
|----------|--------------------------------|---------------|  
| Реализовать портал самообслуживания (Superset + Dremio) | BI-система завязана на DWH, нет self-service | 1 |  
| Обеспечить доступ к данным по доменам | Нет RBAC, доступ управляется вручную через DBA | 1 |  
| Исключить мед. данные из аналитики | PII попадает в отчёты из-за отсутствия фильтров | 1 |  
| Сохранить легаси-системы для клиник | Мед. карты нельзя перенести из MSSQL из-за регуляторных требований | 3 |  
| Подключить новых партнёров (фармацевтика) | Интеграция требует изменений в DWH | 2 |  

---

### **Ключевые проблемы текущей архитектуры**  
1. **Монолитный DWH**:  
   - Узкое место для аналитики, высокие нагрузки.  
   - Невозможно быстро добавить данные нового бизнеса.  
   - **Решение**: Миграция на Iceberg + S3 (Lakehouse).  

2. **Отсутствие Data Mesh**:  
   - Нет владельцев данных в доменах, всё управляется централизованно.  
   - **Решение**: Разделение на домены (финтех, клиники, ИИ) с Data Products.  

3. **Ручное управление доступом**:  
   - Права выдаются DBA, нет аудита.  
   - **Решение**: RBAC через Keycloak + политики в DataHub.  

4. **Устаревшая интеграция (Camel)**:  
   - Не поддерживает event-driven подход.  
   - **Решение**: Замена на Kafka + API Gateway.  

5. **Медленные BI-отчёты**:  
   - Зависимость от ETL в DWH.  
   - **Решение**: Прямой доступ к Iceberg через Dremio.  

---

### **Рекомендации по приоритизации**  
1. **Сначала (1-3 месяца)**:  
   - Запустить DataHub и Kafka.  
   - Назначить владельцев доменов.  
   - Перенести финансовые данные в Iceberg.  

2. **Потом (3-6 месяцев)**:  
   - Настроить Superset + Dremio.  
   - Внедрить RBAC.  

3. **В конце (6-12 месяцев)**:  
   - Перевести клиники на агрегированные данные (без PII).  
   - Подключить фармацевтику через Kafka.  

**Итог**: Фокус на разделение доменов и отказ от зависимости от DWH.

| 🥇 | **Проблема**                                                                |
| -- | --------------------------------------------------------------------------- |
| 1  | Невозможно собрать единую картину бизнеса из-за изолированности направлений |
| 2  | Объёмы и вариативность данных приводят к лавине ETL и медленным отчётам     |
| 3  | Старый монолитный DWH (SQL Server 2008) не выдерживает нагрузку             |
| 4  | Отсутствует доменное деление и зона ответственности команд                  |
| 5  | Нет BI-среды самообслуживания — отчёты строят вручную и долго               |


### 🚀 **Оптимизированный план трансформации данных**  
*(Сгруппированный по фазам, с фокусом на бизнес-результаты)*  

---

#### **🔴 Фаза 1: Критические изменения (0-3 месяца)**  
**Цель**: Ликвидировать блокеры для self-service аналитики.  

| **Действие** | **Технологии** | **KPI** |  
|--------------|----------------|---------|  
| **1. Миграция DWH → Lakehouse** | Iceberg + S3, Airflow | Уменьшение времени генерации отчётов с часов до минут |  
| **2. Разделение на домены** | DataHub (владельцы данных), Kafka | Чёткие границы: финтех, клиники, ИИ |  
| **3. Внедрение RBAC** | Keycloak + DataHub политики | 100% автоматизированных запросов на доступ |  
| **4. Запуск BI-портала** | Superset + Dremio | 80% отчётов строятся без участия ИТ |  
| **5. Каталог метаданных** | DataHub | 100% Data Products с документацией |  

**Риски**:  
- Сопротивление команд при переходе на домены → Провести воркшопы по Data Mesh.  
- Задержки миграции DWH → Начать с финтеха (наименее регуляторно-зависимого).  

---

#### **🟠 Фаза 2: Оптимизация (3-6 месяцев)**  
**Цель**: Устранить технический долг, мешающий масштабированию.  

| **Действие** | **Технологии** | **KPI** |  
|--------------|----------------|---------|  
| **1. Замена Camel на Kafka** | Kafka, Debezium | Уменьшение времени интеграции новых партнёров на 70% |  
| **2. Фильтрация PII** | Great Expectations, dbt | 0 инцидентов с утечкой мед. данных |  
| **3. Ingestion API** | FastAPI, OpenAPI | 5+ подключённых партнёров без ETL |  
| **4. Централизация метаданных** | DataHub + Kafka hooks | 95% метаданных в одном месте |  

**Лайфхаки**:  
- Для PII: Автоматическое маскирование в Dremio через SQL-правила.  
- Для Kafka: Использовать схему Avro + Confluent Schema Registry.  

---

#### **🟢 Фаза 3: Доработки (6-12 месяцев)**  
**Цель**: Подготовка к полному Data Mesh.  

| **Действие** | **Технологии** | **KPI** |  
|--------------|----------------|---------|  
| **1. Semantic Layer** | dbt + MetricFlow | Единые KPI для всех BI-инструментов |  
| **2. Миграция легаси-клиник** | CDC (Debezium) + Iceberg | 100% агрегатов в Lakehouse |  
| **3. Data Quality Dashboard** | Great Expectations + Superset | Мониторинг 100% критичных таблиц |  

---

### 📊 **Сводка по технологиям**  
| **Категория** | **Основные инструменты** | **Альтернативы** |  
|---------------|--------------------------|-------------------|  
| **Хранилище** | Iceberg + S3 | Delta Lake, Hudi |  
| **Каталог** | DataHub | Amundsen, Alation |  
| **BI** | Superset + Dremio | Power BI + Trino |  
| **Доступ** | Keycloak | OPA, Apache Ranger |  

---

### 💡 **Ключевые принципы для команды**  
1. **Data as a Product**: Каждый домен отвечает за свои данные.  
2. **Self-Service First**: Аналитики работают без DBA.  
3. **Automate Governance**: RBAC, quality checks и lineage — автоматизированы.  

**Пример**:  
Финтех-домен публикует Iceberg-таблицу `transactions` с:  
- Документацией в DataHub  
- SLA = 99.9% uptime  
- Тегами `#finance`, `#pii_masked`  

---

### 🎯 **Итоговый эффект через год**  
- **Для бизнеса**: Отчёты за минуты вместо часов, лёгкое подключение партнёров.  
- **Для ИТ**: Никаких ручных ETL, прозрачность данных через DataHub.  
- **Для compliance**: Контроль PII и аудит доступа.  

**Что делать сейчас**:  
1. Создать рабочую группу по миграции DWH.  
2. Назначить владельцев доменов.  
3. Развернуть DataHub и Superset PoC.9